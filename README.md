# Ethical Decision-Making in Autonomous Vehicles: From Rule-Based Simulation to Machine Learning

**Dissertation Topic:**  
_Research and application of ethical decision-making frameworks in the design and development of a prototype of an autonomous vehicle_  
**Author:** Dilasha Ghimire

This project demonstrates how **Utilitarianism**, **Deontological Ethics**, and **Virtue Ethics** can be implemented in autonomous vehicle decision-making.  
It extends from theoretical testing â†’ simulation in CARLA â†’ dataset generation â†’ ML model training â†’ interactive comparison. It is designed as a proof-of-concept for academic research.

---

## ğŸ“Œ Project Overview

This project explores the integration of ethical decision-making into autonomous vehicle systems using both rule-based logic (â€œteacherâ€) and machine learning (â€œstudentâ€). The development process begins with theoretical testing of the teacherâ€™s ethical rules to ensure consistent and logical outcomes. These rules are then tested in the CARLA simulator to visualize behavior in realistic driving scenarios. An adapter is introduced to refine the teacherâ€™s decisions using additional factors such as relative risk, vehicle speed, and child presence. Synthetic datasets generated from these refined teacher rules are used to train student models that imitate the decision-making process. The project concludes with an interactive Streamlit application that allows users to compare the teacherâ€™s decisions with the predictions of the student model for the same scenario inputs.

---

## ğŸ§  Ethical Frameworks Implemented

- **Utilitarianism**: Minimize overall harm
- **Deontology**: Follow moral rules regardless of outcomes
- **Virtue Ethics**: Focus on moral character and context

---

## ğŸš€ Project Development Flow

### 1. **Initial theoretical testing**

- Used `run_simulation.py` and `ethics_logic_reporting.py` to test ethical decision-making rules in a purely theoretical, text-based form.
- **Purpose:** Validate that the ethical rules produce logically consistent decisions in a text-based form before adding complexity.

---

### 2. **Visual simulation (CARLA)**

- Used `simulation.py` and `ethics_engine.py` to integrate the rules into the CARLA simulator for visual, interactive testing.
- **Purpose:** Observe rule behavior in a realistic, repeatable 3D environment to refine decision logic.

---

### 3. **Dataset creation (teacher labels)**

- Files: `rules_adapter.py`, `label_data.py`
- Original `ethics_engine.py` unchanged.

  - `rules_adapter.py` acts as a bridge between the original ethical decision rules and additional context features. It refines the decisions by incorporating the following:

    - `left_risk`, `right_risk` (0â€“1)
    - `speed_kph` (0â€“70)
    - `child_present` (0/1)

  - `label_data.py` generates synthetic scenarios containing these features, uses the adapter to assign an action for each scenario.

- Saved three CSVs to `labeled_data/`: one per ethical mode.
- **Purpose:** Generate a large, labeled dataset from the refined rules so it can be used for ML training.

---

### 4. **Train the ML â€œstudentâ€**

- File: `train_models.py`
- Features used:
  - Categorical: `name` (type of ethical dilemma scenario), `child_present`
  - Numeric: `left_risk`, `right_risk`, `speed_kph`
- **Purpose:** Teach a model to replicate the rule-based teacherâ€™s decision-making.

---

### 5. **Interactive demo (â€œgameâ€)**

- Built a Streamlit app (`app.py`) with:
  - Scenario: radio buttons (`car_vs_pedestrian` / `car_vs_car` / `pedestrian_vs_pedestrian`)
  - Ethical mode: radio buttons (`utilitarian` / `deontological` / `virtue`)
  - Inputs:
    - sliders for `left_risk`, `right_risk`, `speed_kph`
    - dropdown for `child_present`
- The app shows Teacher (rules) vs Student (ML) decisions side-by-side for the same inputs.
- **Purpose:** Provide a transparent and intuitive side-by-side comparison of rule-based and ML decisions for the same user-defined scenario, enabling easy demonstration of the decision-making pipeline.

---

## ğŸ›  Project Structure

```bash
EthicalAV/
â”œâ”€â”€ labeled_data/                 # CSV datasets per mode (generated by label_data.py)
â”œâ”€â”€ models/                       # Trained ML models (one per mode)
â”œâ”€â”€ recordings/                   # CARLA video recordings
â”œâ”€â”€ results/                      # Logs of decisions (CSV)
â”œâ”€â”€ screenshots/                  # CARLA scenario screenshots
â”œâ”€â”€ visualizations/               # Saved plots & summary metrics (generated)
â”œâ”€â”€ app.py                        # Streamlit demo (Teacher vs Student)
â”œâ”€â”€ ethics_engine.py              # Base ethical decision rules
â”œâ”€â”€ ethics_logic_reporting.py     # Text-based testing of rules
â”œâ”€â”€ evaluate_confusion_matrix.py  # Builds confusion matrix plots per mode
â”œâ”€â”€ label_data.py                 # Synthetic dataset generator (teacher labels)
â”œâ”€â”€ metrics_runner.py             # Evaluates metrics (acc/prec/recall/F1/AUC/spec)
â”œâ”€â”€ rules_adapter.py              # Refines base rules with extra features
â”œâ”€â”€ run_simulation.py             # Runs theoretical rules
â”œâ”€â”€ simulation.py                 # CARLA-based visual simulation
â””â”€â”€ train_models.py               # ML model training script
```

---

## â–¶ï¸ Getting Started

### 1. Prerequisites

- CARLA Simulator, tested with v0.10.0
  (Download: https://carla.org/)
- Python 3.7+
- NVIDIA GPU (recommended)

### 2. Setup

```bash
python -m pip install numpy pandas scikit-learn joblib streamlit carla matplotlib
```

### 3. Run the theoretical simulation

```bash
python run_simulation.py
```

### 4. Run a CARLA simulation

```bash
python simulation.py
```

### 5. Generate labels

```bash
python label_data.py
```

### 6. Train models

```bash
python train_models.py
```

### 7. Run interactive demo

```bash
python -m streamlit run app.py
```

### 8. (Optional) Generate evaluation visuals & metrics

```bash
# Build confusion matrix images
python evaluate_confusion_matrix.py

# Compute and save metrics summary CSV
python metrics_runner.py
```

---

## ğŸ“Š Output

- **From run_simulation.py / simulation.py**: Screenshots, logs, optional CARLA recordings
- **From label_data.py**: Three CSV datasets in `labeled_data/`
- **From train_models.py**: Three `.pkl` models in `models/`
- **From app.py**: Side-by-side Teacher vs Student predictions
- **From evaluate_confusion_matrix.py**:
  PNG confusion matrices saved to `visualizations/` (one per mode)
- **From metrics_runner.py**: `visualizations/model_metrics_summary.csv` with Accuracy, Precision/Recall/F1 (macro), Specificity (macro), and AUC-ROC (macro-OvR)

---

## ğŸ“ Academic Relevance

This project provides a practical framework to:

- Compare theoretical ethical models in autonomous driving.
- Validate them visually in CARLA.
- Train ML models to imitate them.
- Demonstrate results interactively.

It demonstrates that rule-based ethical frameworks can be logically applied to AVs and yield consistent, transparent behavior in simulated environments.

---

## ğŸ“ Acknowledgements

- Coventry University
- Softwarica College of IT & E-commerce
- Supervisor: Mr. Manoj Shrestha

---

## âœ… License

This project is for academic demonstration purposes only. Not intended for commercial use or real-world deployment.
